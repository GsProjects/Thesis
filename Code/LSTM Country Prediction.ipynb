{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gspc/anaconda3/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n",
      "/home/gspc/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import mysql.connector\n",
    "import gc\n",
    "import math\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from patsy import dmatrices\n",
    "from pandas.core import datetools\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "sns.set_style('darkgrid')\n",
    "pd.options.display.float_format = '{:,.2f}'.format\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection():\n",
    "    cnx2 = mysql.connector.connect(host='localhost',\n",
    "                                   user='root', password='MyNewPass',\n",
    "                                   database='Weather_Data')\n",
    "    return cnx2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_data():\n",
    "    conn = create_connection()\n",
    "    cursor = conn.cursor()\n",
    "    print('Extracting Data')\n",
    "    query = \"Select * from weather where Observation_date <= '2018-06-01 00:00:00';\"\n",
    "    cursor.execute(query, )\n",
    "    result = cursor.fetchall()\n",
    "    print('Extracted Data')\n",
    "        \n",
    "    cursor.close()\n",
    "    conn.close()\n",
    "    \n",
    "    return result\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def null_values(data):\n",
    "    print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_structure(data):\n",
    "    cols = ['date', 'rain', 'temp', 'wetb', 'dewpt','vappr', 'rhum', 'msl', 'wdsp', 'wddir','height','latitude', 'longitude', 'station','county']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    \n",
    "    #null_values(data)\n",
    "    data.fillna(0, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_time(data):\n",
    "    data['date'] = pd.to_datetime(data['date'])\n",
    "    data['year'] = data['date'].dt.year.astype(np.uint16)\n",
    "    data['month'] = data['date'].dt.month.astype(np.uint8)\n",
    "    data['day'] = data['date'].dt.day.astype(np.uint8)\n",
    "    data['hour'] = data['date'].dt.hour.astype(np.uint8)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_season(data):\n",
    "    data['season'] = pd.cut(data['month'], bins=[0,1,4,7,10,14], labels=['Winter','Spring','Summer','Autumn','Winter2']).str.replace('Winter2','Winter')\n",
    "    data['season'] = data['season'].astype('category')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_features_to_categorical(data):\n",
    "    #data['year'] = data['year'].astype(str)\n",
    "    #data['month'] = data['month'].astype(str)\n",
    "    #data['day'] = data['day'].astype(str)\n",
    "    #data['hour'] = data['hour'].astype(str)\n",
    "    \n",
    "    data['year'] = data['year'].astype('category')\n",
    "    data['month'] = data['month'].astype('category')\n",
    "    data['day'] = data['day'].astype('category')\n",
    "    data['hour'] = data['hour'].astype('category')\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_wdsp(data):\n",
    "    data['wdsp'] = data['wdsp'] * 1.852\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_rhum_values(data):\n",
    "    print('Updating relative humidity values <= 0')\n",
    "    rhum_mean = data['rhum'].mean()\n",
    "    data.loc[data['rhum'] <= 0, 'rhum'] = rhum_mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_wetb_values(data):\n",
    "    print('Updating wet bulb air temperature values <= 0')\n",
    "    wetb_mean = data['wetb'].mean()\n",
    "    data.loc[data['wetb'] <= -40, 'wetb'] = wetb_mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_dewpt_values(data):\n",
    "    print('Updating dew point air temperature values <= 0')\n",
    "    dewpt_mean = data['dewpt'].mean()\n",
    "    data.loc[data['dewpt'] <= -20,'dewpt'] = dewpt_mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_msl_values(data):\n",
    "    print('Updating mean sea level pressure values <= 0')\n",
    "    msl_mean = data['msl'].mean() \n",
    "    data.loc[data['msl'] < 940, 'msl'] = msl_mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_vappr_values(data):\n",
    "    print('Updating vapour pressure values <= 0')\n",
    "    vappr_mean = data['vappr'].mean()\n",
    "    data.loc[data['vappr'] <= 0, 'vappr'] = vappr_mean\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_categories(data):\n",
    "    print('Binarizing categorical data')\n",
    "    \n",
    "    categorical_columns = []\n",
    "\n",
    "    for col in data.columns:\n",
    "        if isinstance(data[col][0], str):\n",
    "            print('Changing ', col, ' to categorical')\n",
    "            categorical_columns.append(col)\n",
    "            encoder = LabelBinarizer()\n",
    "            data[col] = encoder.fit_transform(data[col])\n",
    "            \n",
    "    #data = delete_original_categories(categorical_columns, data)        \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_original_categories(categorical_columns, data):\n",
    "    print('Deleting original categories')\n",
    "    for col in categorical_columns:\n",
    "        if col in data.columns:\n",
    "            del(data[col])\n",
    "            gc.collect()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_unwanted_features(data):\n",
    "    print('Removing features')\n",
    "    data = data.drop( columns = ['date', 'height', 'latitude', 'longitude', 'station', 'county'])\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_lagged_features(data, shift_freq, shift_name):\n",
    "    print('Generating time lagged features')\n",
    "    \n",
    "    temp = data\n",
    "    temp.drop(columns=['season'], inplace=True)\n",
    "    \n",
    "    cols = ['year', 'month', 'day', 'hour', 'rain', 'temp', 'wetb', 'dewpt','vappr', 'rhum', 'msl', 'wdsp', 'wddir']\n",
    "    new_cols = []\n",
    "    \n",
    "    for item in cols:\n",
    "        item = item + shift_name \n",
    "        new_cols.append(item)\n",
    "    \n",
    "    temp = temp.shift(shift_freq)\n",
    "    temp.columns = new_cols\n",
    "    \n",
    "    temp.reset_index(drop=True, inplace=True)\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    data = data.join(temp)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_data(data):\n",
    "    data = data.sort_values(['year','month','day','hour'])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_data(data):\n",
    "    #may need to drop season feature then recreate it\n",
    "    #['rain','temp', 'wetb', 'dewpt', 'vappr', 'rhum', 'msl', 'wdsp', 'wddir']\n",
    "    print('Aggregating Data')\n",
    "    season = data['season']\n",
    "    data = data.groupby( by=['year','month','day','hour']).mean().reset_index()\n",
    "    sorted_data = sort_data(data)\n",
    "    data['season'] = season\n",
    "    \n",
    "    print(len(sorted_data),' observations available for training')\n",
    "    \n",
    "    return sorted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_supervised(data):\n",
    "    temp = data\n",
    "    temp = temp['rain'].shift(-1)\n",
    "    \n",
    "    data['target_rainfall'] = temp\n",
    "    \n",
    "    data.drop(data.index[len(data)-1], inplace=True)\n",
    "    data.drop(data.index[0], inplace=True)\n",
    "    data.fillna(data.mean(), inplace=True)    \n",
    "    data.reset_index(inplace=True, drop=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_data(data):\n",
    "    print('Normalising test data')\n",
    "    data.drop(columns = ['target_rainfall'], inplace=True)\n",
    "    column_names = data.columns\n",
    "    scaler = MinMaxScaler()\n",
    "    normalised_data = scaler.fit_transform(data)\n",
    "\n",
    "    normalised_data = pd.DataFrame(normalised_data, columns=column_names)\n",
    "    \n",
    "    return [normalised_data, scaler]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    print('Getting test set')\n",
    "    \n",
    "    #validate on last 30 days without retraining model after each prediction\n",
    "    test_data = -30\n",
    "    \n",
    "    \n",
    "    train = data[:test_data]\n",
    "    test = data[test_data:]\n",
    "    \n",
    "    Xtrain, Ytrain = train.loc[:, train.columns != 'rain'], train.loc[:, train.columns == 'rain']\n",
    "    Xtest, Ytest = test.loc[:, test.columns != 'rain'], test.loc[:, test.columns == 'rain']\n",
    "    \n",
    "    Xtrain = Xtrain.values.astype('float32') # convert to numpy array\n",
    "    Xtest = Xtest.values.astype('float32')\n",
    "    \n",
    "    Xtrain = Xtrain.reshape((Xtrain.shape[0], 1, Xtrain.shape[1]))\n",
    "    #Xtest = Xtest.reshape((Xtest.shape[0], 1, Xtest.shape[1]))\n",
    "    \n",
    "    print(Xtrain.shape)\n",
    "    print(Xtest.shape)\n",
    "    \n",
    "    return [Xtrain, Ytrain, Xtest, Ytest]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lstm(Xtrain, Ytrain, Xtest, Ytest):\n",
    "    # initialise train model\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(100, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    model.add(Dense(1)) #determines the number of outputs\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    \n",
    "    # batch size determines how many input observations the network sees before it can update weigths\n",
    "    model.fit(Xtrain, Ytrain, epochs=50, batch_size=100, verbose=1, shuffle=False)\n",
    "    \n",
    "    train_weigths = model.get_weights() # get weights of trained model to use for initialisation of prediction model\n",
    "    \n",
    "    # initialise test model\n",
    "    \n",
    "    test_model = Sequential()\n",
    "    test_model.add(LSTM(100, input_shape=(Xtrain.shape[1], Xtrain.shape[2])))\n",
    "    test_model.add(Dense(1)) #determines the number of outputs\n",
    "    test_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    test_model.set_weights(train_weigths)\n",
    "    \n",
    "    return test_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lstm(test_model, Xtest, Ytest, scaler):\n",
    "    Ytest = Ytest.values\n",
    "    predicted_output = []\n",
    "    Xtest = Xtest.reshape(len(Xtest),1,25)\n",
    "    predicted_output.append(test_model.predict(Xtest, batch_size=len(Xtest)))\n",
    "    print('RMSE: ', math.sqrt(mean_squared_error(Ytest, predicted_output[0])))\n",
    "    \n",
    "    #Code for sequential predictions\n",
    "    '''for i in range(len(Xtest)):\n",
    "        x_input = Xtest[i]\n",
    "        y_output = Ytest[i]\n",
    "        x_input = x_input.reshape(1,1,25)\n",
    "        predicted_output.append(test_model.predict(x_input, batch_size=len(Xtest)))\n",
    "        print(predicted_output)\n",
    "        \n",
    "        #print('RMSE: ', math.sqrt(mean_squared_error(y_output, predicted_output)))\n",
    "        #print('Original value: ', y_output, ' Predicted value: ', predicted_output)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting Data\n",
      "Extracted Data\n",
      "Removing features\n",
      "Binarizing categorical data\n",
      "Changing  season  to categorical\n",
      "Updating relative humidity values <= 0\n",
      "Updating wet bulb air temperature values <= 0\n",
      "Updating dew point air temperature values <= 0\n",
      "Updating mean sea level pressure values <= 0\n",
      "Updating vapour pressure values <= 0\n",
      "Aggregating Data\n",
      "266617  observations available for training\n",
      "Generating time lagged features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>hour</th>\n",
       "      <th>rain</th>\n",
       "      <th>temp</th>\n",
       "      <th>wetb</th>\n",
       "      <th>dewpt</th>\n",
       "      <th>vappr</th>\n",
       "      <th>rhum</th>\n",
       "      <th>msl</th>\n",
       "      <th>wdsp</th>\n",
       "      <th>wddir</th>\n",
       "      <th>year1hr</th>\n",
       "      <th>month1hr</th>\n",
       "      <th>day1hr</th>\n",
       "      <th>hour1hr</th>\n",
       "      <th>rain1hr</th>\n",
       "      <th>temp1hr</th>\n",
       "      <th>wetb1hr</th>\n",
       "      <th>dewpt1hr</th>\n",
       "      <th>vappr1hr</th>\n",
       "      <th>rhum1hr</th>\n",
       "      <th>msl1hr</th>\n",
       "      <th>wdsp1hr</th>\n",
       "      <th>wddir1hr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.90</td>\n",
       "      <td>6.93</td>\n",
       "      <td>5.74</td>\n",
       "      <td>9.22</td>\n",
       "      <td>86.30</td>\n",
       "      <td>997.62</td>\n",
       "      <td>29.82</td>\n",
       "      <td>229.00</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "      <td>nan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.17</td>\n",
       "      <td>9.50</td>\n",
       "      <td>88.80</td>\n",
       "      <td>997.18</td>\n",
       "      <td>31.11</td>\n",
       "      <td>230.00</td>\n",
       "      <td>1,988.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.14</td>\n",
       "      <td>7.90</td>\n",
       "      <td>6.93</td>\n",
       "      <td>5.74</td>\n",
       "      <td>9.22</td>\n",
       "      <td>86.30</td>\n",
       "      <td>997.62</td>\n",
       "      <td>29.82</td>\n",
       "      <td>229.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8.03</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.86</td>\n",
       "      <td>9.97</td>\n",
       "      <td>92.40</td>\n",
       "      <td>996.52</td>\n",
       "      <td>30.19</td>\n",
       "      <td>226.00</td>\n",
       "      <td>1,988.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.30</td>\n",
       "      <td>7.93</td>\n",
       "      <td>7.14</td>\n",
       "      <td>6.17</td>\n",
       "      <td>9.50</td>\n",
       "      <td>88.80</td>\n",
       "      <td>997.18</td>\n",
       "      <td>31.11</td>\n",
       "      <td>230.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.35</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.29</td>\n",
       "      <td>93.30</td>\n",
       "      <td>995.71</td>\n",
       "      <td>30.93</td>\n",
       "      <td>220.00</td>\n",
       "      <td>1,988.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.73</td>\n",
       "      <td>8.03</td>\n",
       "      <td>7.50</td>\n",
       "      <td>6.86</td>\n",
       "      <td>9.97</td>\n",
       "      <td>92.40</td>\n",
       "      <td>996.52</td>\n",
       "      <td>30.19</td>\n",
       "      <td>226.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1988</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.19</td>\n",
       "      <td>8.74</td>\n",
       "      <td>8.25</td>\n",
       "      <td>7.68</td>\n",
       "      <td>10.56</td>\n",
       "      <td>93.40</td>\n",
       "      <td>994.84</td>\n",
       "      <td>30.74</td>\n",
       "      <td>218.00</td>\n",
       "      <td>1,988.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.35</td>\n",
       "      <td>7.88</td>\n",
       "      <td>7.34</td>\n",
       "      <td>10.29</td>\n",
       "      <td>93.30</td>\n",
       "      <td>995.71</td>\n",
       "      <td>30.93</td>\n",
       "      <td>220.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year  month  day  hour  rain  temp  wetb  dewpt  vappr  rhum    msl  wdsp  \\\n",
       "0  1988      1    1     0  0.14  7.90  6.93   5.74   9.22 86.30 997.62 29.82   \n",
       "1  1988      1    1     1  0.30  7.93  7.14   6.17   9.50 88.80 997.18 31.11   \n",
       "2  1988      1    1     2  0.73  8.03  7.50   6.86   9.97 92.40 996.52 30.19   \n",
       "3  1988      1    1     3  0.36  8.35  7.88   7.34  10.29 93.30 995.71 30.93   \n",
       "4  1988      1    1     4  0.19  8.74  8.25   7.68  10.56 93.40 994.84 30.74   \n",
       "\n",
       "   wddir  year1hr  month1hr  day1hr  hour1hr  rain1hr  temp1hr  wetb1hr  \\\n",
       "0 229.00      nan       nan     nan      nan      nan      nan      nan   \n",
       "1 230.00 1,988.00      1.00    1.00     0.00     0.14     7.90     6.93   \n",
       "2 226.00 1,988.00      1.00    1.00     1.00     0.30     7.93     7.14   \n",
       "3 220.00 1,988.00      1.00    1.00     2.00     0.73     8.03     7.50   \n",
       "4 218.00 1,988.00      1.00    1.00     3.00     0.36     8.35     7.88   \n",
       "\n",
       "   dewpt1hr  vappr1hr  rhum1hr  msl1hr  wdsp1hr  wddir1hr  \n",
       "0       nan       nan      nan     nan      nan       nan  \n",
       "1      5.74      9.22    86.30  997.62    29.82    229.00  \n",
       "2      6.17      9.50    88.80  997.18    31.11    230.00  \n",
       "3      6.86      9.97    92.40  996.52    30.19    226.00  \n",
       "4      7.34     10.29    93.30  995.71    30.93    220.00  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = select_data()\n",
    "data = change_structure(data)\n",
    "data = split_time(data)\n",
    "data = generate_season(data)\n",
    "#data = time_features_to_categorical(data)\n",
    "data = remove_unwanted_features(data)\n",
    "data = convert_wdsp(data)\n",
    "data = sort_data(data)\n",
    "data = binarize_categories(data)\n",
    "\n",
    "data = update_rhum_values(data)\n",
    "data = update_wetb_values(data)\n",
    "data = update_dewpt_values(data)\n",
    "data = update_msl_values(data)\n",
    "data = update_vappr_values(data)\n",
    "\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data = aggregate_data(data)\n",
    "data = time_lagged_features(data, 1, '1hr')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_to_supervised(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalising test data\n"
     ]
    }
   ],
   "source": [
    "normalised_data = normalise_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting test set\n",
      "(266585, 1, 25)\n",
      "(30, 25)\n",
      "CPU times: user 20 ms, sys: 16 ms, total: 36 ms\n",
      "Wall time: 31.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time lstm_data = train_test_split(normalised_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "266585/266585 [==============================] - 9s 33us/step - loss: 0.0012\n",
      "Epoch 2/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 9.5327e-04\n",
      "Epoch 3/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 9.3034e-04\n",
      "Epoch 4/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 9.1219e-04\n",
      "Epoch 5/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 9.0116e-04\n",
      "Epoch 6/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.9425e-04\n",
      "Epoch 7/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.8939e-04\n",
      "Epoch 8/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.8536e-04\n",
      "Epoch 9/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.8197e-04\n",
      "Epoch 10/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.7920e-04\n",
      "Epoch 11/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.7675e-04\n",
      "Epoch 12/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.7459e-04\n",
      "Epoch 13/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.7272e-04\n",
      "Epoch 14/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.7091e-04\n",
      "Epoch 15/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6926e-04\n",
      "Epoch 16/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6777e-04\n",
      "Epoch 17/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6615e-04\n",
      "Epoch 18/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6497e-04\n",
      "Epoch 19/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6317e-04\n",
      "Epoch 20/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.6221e-04\n",
      "Epoch 21/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.6069e-04\n",
      "Epoch 22/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.5936e-04\n",
      "Epoch 23/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.5817e-04\n",
      "Epoch 24/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.5682e-04\n",
      "Epoch 25/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.5552e-04\n",
      "Epoch 26/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.5426e-04\n",
      "Epoch 27/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.5292e-04\n",
      "Epoch 28/50\n",
      "266585/266585 [==============================] - 8s 30us/step - loss: 8.5176e-04\n",
      "Epoch 29/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.5035e-04\n",
      "Epoch 30/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4900e-04\n",
      "Epoch 31/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4752e-04\n",
      "Epoch 32/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4635e-04\n",
      "Epoch 33/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4527e-04\n",
      "Epoch 34/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4385e-04\n",
      "Epoch 35/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4255e-04\n",
      "Epoch 36/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4186e-04\n",
      "Epoch 37/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.4067e-04\n",
      "Epoch 38/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3964e-04\n",
      "Epoch 39/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3873e-04\n",
      "Epoch 40/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3793e-04\n",
      "Epoch 41/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3711e-04\n",
      "Epoch 42/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3670e-04\n",
      "Epoch 43/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3665e-04\n",
      "Epoch 44/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3637e-04\n",
      "Epoch 45/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3634e-04\n",
      "Epoch 46/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3633e-04\n",
      "Epoch 47/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3615e-04\n",
      "Epoch 48/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3519e-04\n",
      "Epoch 49/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3408e-04\n",
      "Epoch 50/50\n",
      "266585/266585 [==============================] - 8s 31us/step - loss: 8.3207e-04\n",
      "CPU times: user 11min 2s, sys: 42.3 s, total: 11min 45s\n",
      "Wall time: 6min 47s\n"
     ]
    }
   ],
   "source": [
    "%time test_model = train_lstm(lstm_data[0], lstm_data[1], lstm_data[2], lstm_data[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  0.010577342755437966\n"
     ]
    }
   ],
   "source": [
    "test_lstm(test_model, lstm_data[2], lstm_data[3], normalised_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Important steps\n",
    "\n",
    "Shift data so its supervised learning problem \n",
    "\n",
    "Aggregate data (for future iterations)\n",
    "\n",
    "Normalise data using standard scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xgboost 1st Run (Try on cpu and gpu)\n",
    "\n",
    "Raw features only - remove height, station, county, longitude and latitude\n",
    "\n",
    "### Xgboost 2nd Run\n",
    "\n",
    "Shift features to include previous hour. Will first only include the rainfall from the previous hour\n",
    "\n",
    "### Xgboost 3rd Run\n",
    "\n",
    "Shift features to include 2 hours previous \n",
    "\n",
    "### Xgboost 3rd Run\n",
    "\n",
    "Shift features to include 1 **and** 2 hours previous \n",
    "\n",
    "\n",
    "## Potential Features\n",
    "minus the monthly, yearly , seasonal average, lagged features, median values?\n",
    "\n",
    "aggregate data, difference between current and previous values\n",
    "\n",
    "num splits equal to num distinct years by 12 (months)\n",
    "\n",
    "31 * 12"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
